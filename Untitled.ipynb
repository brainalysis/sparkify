{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8e2b7568-a569-48be-89ec-28bd003dd61e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "# from databricks import koalas as ks , we do not neven need koalsa, because it is now built in with databricks\n",
    "import pyspark.pandas as ps\n",
    "from pyspark.sql import DataFrame as SparkDataFrame\n",
    "\n",
    "from pyspark.ml.feature import VectorAssembler,VectorIndexer,OneHotEncoder,StringIndexer\n",
    "from pyspark.ml import Pipeline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b318cebc-02af-412b-9ad4-7d1bc7842d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pyspark import keyword_only  ## < 2.0 -> pyspark.ml.util.keyword_only\n",
    "from pyspark.ml import Transformer\n",
    "from pyspark.ml.param.shared import HasInputCol, HasOutputCol, Param, Params, TypeConverters\n",
    "# Available in PySpark >= 2.3.0 \n",
    "from pyspark.ml.util import DefaultParamsReadable, DefaultParamsWritable  \n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import ArrayType, StringType\n",
    "\n",
    "class Connector(\n",
    "        Transformer, HasInputCol, HasOutputCol,\n",
    "        # Credits https://stackoverflow.com/a/52467470\n",
    "        # by https://stackoverflow.com/users/234944/benjamin-manns\n",
    "        DefaultParamsReadable, DefaultParamsWritable):\n",
    "\n",
    "\n",
    "    @keyword_only\n",
    "    def __init__(self, inputCol=None, outputCol=None):\n",
    "        super(Connector, self).__init__()\n",
    "        kwargs = self._input_kwargs\n",
    "        self.setParams(**kwargs)\n",
    "\n",
    "    @keyword_only\n",
    "    def setParams(self, inputCol=None, outputCol=None,):\n",
    "        kwargs = self._input_kwargs\n",
    "        return self._set(**kwargs)\n",
    "\n",
    "\n",
    "    # Required in Spark >= 3.0\n",
    "    def setInputCol(self, value):\n",
    "        \"\"\"\n",
    "        Sets the value of :py:attr:`inputCol`.\n",
    "        \"\"\"\n",
    "        return self._set(inputCol=value)\n",
    "\n",
    "    # Required in Spark >= 3.0\n",
    "    def setOutputCol(self, value):\n",
    "        \"\"\"\n",
    "        Sets the value of :py:attr:`outputCol`.\n",
    "        \"\"\"\n",
    "        return self._set(outputCol=value)\n",
    "\n",
    "    def _transform(self, dataset):\n",
    "        dataset = dataset\n",
    "\n",
    "        return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "27349345-5ca4-4e07-a159-e0a53e790118",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pyspark import keyword_only  ## < 2.0 -> pyspark.ml.util.keyword_only\n",
    "from pyspark.ml import Transformer\n",
    "from pyspark.ml.param.shared import HasInputCol, HasOutputCol, Param, Params, TypeConverters\n",
    "# Available in PySpark >= 2.3.0 \n",
    "from pyspark.ml.util import DefaultParamsReadable, DefaultParamsWritable  \n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import ArrayType, StringType\n",
    "\n",
    "class ColumnHandler(\n",
    "        Transformer, HasInputCol, HasOutputCol,\n",
    "        DefaultParamsReadable, DefaultParamsWritable):\n",
    "    \n",
    "    delete_col = Param(Params._dummy(), \"delete_col\", \"delete_col\",\n",
    "                      typeConverter=TypeConverters.toString)\n",
    "    \n",
    "    replace_col = Param(Params._dummy(), \"replace_col\", \"replace_col\",\n",
    "                      typeConverter=TypeConverters.toString)\n",
    "\n",
    "\n",
    "    @keyword_only\n",
    "    def __init__(self, inputCol=None, outputCol=None,delete_col=None,replace_col=None):\n",
    "        super(ColumnHandler, self).__init__()\n",
    "        self.delete_col = Param(self, \"delete_col\", \"\")\n",
    "        self.replace_col = Param(self, \"replace_col\", \"\")\n",
    "        kwargs = self._input_kwargs\n",
    "        self.setParams(**kwargs)\n",
    "\n",
    "    @keyword_only\n",
    "    def setParams(self, inputCol=None, outputCol=None,delete_col=None,replace_col=None):\n",
    "        kwargs = self._input_kwargs\n",
    "        return self._set(**kwargs)\n",
    "    \n",
    "    def setDeleteCol(self, value):\n",
    "        return self._set(delete_col=value)\n",
    "\n",
    "    def getDeleteCol(self):\n",
    "        return self.getOrDefault(self.delete_col)\n",
    "    \n",
    "        \n",
    "    def setReplaceCol(self, value):\n",
    "        return self._set(replace_col=value)\n",
    "\n",
    "    def getReplaceCol(self):\n",
    "        return self.getOrDefault(self.replace_col)\n",
    "\n",
    "\n",
    "    # Required in Spark >= 3.0\n",
    "    def setInputCol(self, value):\n",
    "        \"\"\"\n",
    "        Sets the value of :py:attr:`inputCol`.\n",
    "        \"\"\"\n",
    "        return self._set(inputCol=value)\n",
    "\n",
    "    # Required in Spark >= 3.0\n",
    "    def setOutputCol(self, value):\n",
    "        \"\"\"\n",
    "        Sets the value of :py:attr:`outputCol`.\n",
    "        \"\"\"\n",
    "        return self._set(outputCol=value)\n",
    "\n",
    "    def _transform(self, dataset):\n",
    "        delete_col = self.getDeleteCol()\n",
    "        replace_col = self.getReplaceCol()\n",
    "        \n",
    "        dataset = dataset.drop(*delete_col) \n",
    "        dataset = dataset.withColumnRenamed(replace_col,delete_col) \n",
    "\n",
    "        return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ec713d48-371d-4b3e-930d-956e4378299b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pyspark import keyword_only  ## < 2.0 -> pyspark.ml.util.keyword_only\n",
    "from pyspark.ml import Transformer\n",
    "from pyspark.ml.param.shared import HasInputCol, HasOutputCol, Param, Params, TypeConverters\n",
    "# Available in PySpark >= 2.3.0 \n",
    "from pyspark.ml.util import DefaultParamsReadable, DefaultParamsWritable  \n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import ArrayType, StringType\n",
    "\n",
    "class Custom_OneHotEncoder(\n",
    "        Transformer, HasInputCol, HasOutputCol,\n",
    "        DefaultParamsReadable, DefaultParamsWritable):\n",
    "    \n",
    "    input_columns = Param(Params._dummy(), \"input_columns\", \"input_columns\",\n",
    "                      typeConverter=TypeConverters.toListString)\n",
    "    \n",
    "    output_column = Param(Params._dummy(), \"output_column\", \"output_column\",\n",
    "                      typeConverter=TypeConverters.toString)\n",
    "\n",
    "\n",
    "    @keyword_only\n",
    "    def __init__(self, inputCol=None, outputCol=None,input_columns=None,output_column=None):\n",
    "        super(Custom_OneHotEncoder, self).__init__()\n",
    "        self.input_columns = Param(self, \"input_columns\", \"\")\n",
    "        self.output_column = Param(self, \"output_column\", \"\")\n",
    "        kwargs = self._input_kwargs\n",
    "        self.setParams(**kwargs)\n",
    "\n",
    "    @keyword_only\n",
    "    def setParams(self, inputCol=None, outputCol=None,input_columns=None,output_column=None):\n",
    "        kwargs = self._input_kwargs\n",
    "        return self._set(**kwargs)\n",
    "    \n",
    "    def setInput_columns(self, value):\n",
    "        return self._set(input_columns=value)\n",
    "\n",
    "    def getInput_columns(self):\n",
    "        return self.getOrDefault(self.input_columns)\n",
    "    \n",
    "        \n",
    "    def setOutput_column(self, value):\n",
    "        return self._set(output_column=value)\n",
    "\n",
    "    def getOutput_column(self):\n",
    "        return self.getOrDefault(self.output_column)\n",
    "\n",
    "\n",
    "    # Required in Spark >= 3.0\n",
    "    def setInputCol(self, value):\n",
    "        \"\"\"\n",
    "        Sets the value of :py:attr:`inputCol`.\n",
    "        \"\"\"\n",
    "        return self._set(inputCol=value)\n",
    "\n",
    "    # Required in Spark >= 3.0\n",
    "    def setOutputCol(self, value):\n",
    "        \"\"\"\n",
    "        Sets the value of :py:attr:`outputCol`.\n",
    "        \"\"\"\n",
    "        return self._set(outputCol=value)\n",
    "\n",
    "    def _transform(self, dataset):\n",
    "        \n",
    "        input_cols = self.getInput_columns()\n",
    "        output_col = self.getOutput_column()\n",
    "        \n",
    "        indexer = StringIndexer(inputCols=input_cols,outputCols= [column + str(\"_indexer\") for column in input_cols])\n",
    "        encoder = OneHotEncoder(inputCols=[column + str(\"_indexer\") for column in input_cols] , outputCols= \n",
    "                                [column + str(\"_encoded\") for column in input_cols], dropLast=False)\n",
    "        assembler = VectorAssembler(inputCols= [column + str(\"_encoded\") for column in input_cols],\n",
    "                                    outputCol= output_col)\n",
    "        \n",
    "        \n",
    "\n",
    "        return indexer,encoder,assembler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9b8ed131-f16c-43a9-ba98-355454cddc45",
   "metadata": {},
   "outputs": [],
   "source": [
    "from SparkAutoML.ml_module.preprocessing_module.preprocess_file import Preprocessor\n",
    "from pyspark.sql.types import FloatType\n",
    "from pyspark.sql.types import IntegerType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e07e151a-dcae-454b-9809-18a2322c8430",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data \n",
    "df = ps.read_csv(\"credit.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1eca9b8b-5dbd-4cd8-b961-71f8c6284cab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['LIMIT_BAL', 'SEX', 'EDUCATION', 'MARRIAGE', 'AGE', 'PAY_1', 'PAY_2',\n",
       "       'PAY_3', 'PAY_4', 'PAY_5', 'PAY_6', 'BILL_AMT1', 'BILL_AMT2',\n",
       "       'BILL_AMT3', 'BILL_AMT4', 'BILL_AMT5', 'BILL_AMT6', 'PAY_AMT1',\n",
       "       'PAY_AMT2', 'PAY_AMT3', 'PAY_AMT4', 'PAY_AMT5', 'PAY_AMT6', 'default'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cd56852e-d2e5-462c-b991-91a8fcd1c0f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#def bool_function(df:ks.DataFrame)->ks.DataFrame:\n",
    "def bool_function(df):\n",
    "  df =ps.sql(\"\"\"select *,\n",
    "  case when mean_bal > 50000 then 1 else 0 end as new_bol_sql\n",
    "  from {df}\"\"\")\n",
    "  return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "48b59b38-7b1a-4b74-a45f-dbee2d5a8842",
   "metadata": {},
   "outputs": [],
   "source": [
    "# that is how you can apply the full stack piping in koalas\n",
    "df= (\n",
    "df\n",
    "[['LIMIT_BAL', 'SEX', 'EDUCATION', 'MARRIAGE', 'AGE']]\n",
    ".pipe(lambda x: ps.sql(\"\"\" select * , case when LIMIT_BAL < 100000 then 'low' when LIMIT_BAL between 100000 and 200000 then 'medium' else 'high' end as BAL_CAT from {x}\"\"\"))\n",
    ".pipe(lambda x: ps.sql(\"\"\" select * , case when AGE < 30 then 'youth' when AGE between 30 and 40 then 'yong' else 'mature' end as maturity from {x}\"\"\"))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c93721e1-b45c-4706-9857-6dd73ef61429",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LIMIT_BAL</th>\n",
       "      <th>SEX</th>\n",
       "      <th>EDUCATION</th>\n",
       "      <th>MARRIAGE</th>\n",
       "      <th>AGE</th>\n",
       "      <th>BAL_CAT</th>\n",
       "      <th>maturity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>low</td>\n",
       "      <td>youth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>90000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>34</td>\n",
       "      <td>low</td>\n",
       "      <td>yong</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>low</td>\n",
       "      <td>yong</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>57</td>\n",
       "      <td>low</td>\n",
       "      <td>mature</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>37</td>\n",
       "      <td>low</td>\n",
       "      <td>yong</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   LIMIT_BAL  SEX  EDUCATION  MARRIAGE  AGE BAL_CAT maturity\n",
       "0      20000    2          2         1   24     low    youth\n",
       "1      90000    2          2         2   34     low     yong\n",
       "2      50000    2          2         1   37     low     yong\n",
       "3      50000    1          2         1   57     low   mature\n",
       "4      50000    1          1         2   37     low     yong"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c0194fe0-fa84-429d-856c-ee6a20571dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import (\n",
    "    VectorAssembler,\n",
    "    VectorIndexer,\n",
    "    OneHotEncoder,\n",
    "    StringIndexer,\n",
    "    Imputer,\n",
    "    Normalizer,\n",
    "    StandardScaler,\n",
    ")\n",
    "from pyspark.ml import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ba43d31e-11f2-449f-b700-2a274f005b65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler_aec5fb4e1333"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "145e0d8c-a169-4236-98b4-ea2f224681e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# df.iloc[0,4] = np.nan\n",
    "# df.AGE = df.AGE.astype(float)\n",
    "spark_df = df.to_spark()\n",
    "# spark_df = spark_df.withColumn('AGE', spark_df['AGE'].cast(IntegerType()))\n",
    "train,test = spark_df.randomSplit([.70,.30],seed=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "80d334d4-53c1-4a1f-9c67-37de43693fa5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['LIMIT_BAL', 'SEX', 'EDUCATION', 'MARRIAGE', 'AGE', 'BAL_CAT', 'maturity']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a4c81f2f-58e2-4ebc-967f-e20de8fa4443",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _pipe(num_cols,cat_cols=None, impute=False, impute_strategy='mean', normalize=False, normalize_p=2, \n",
    "          standard_scale =False,standard_scaler_withMean=False,standard_scaler_withStd=True,):\n",
    "    \n",
    "    # first we deploy imputer\n",
    "    if impute:\n",
    "        imputer = Imputer(inputCols=num_cols,outputCols=num_cols,strategy=impute_strategy)\n",
    "    else:\n",
    "        imputer = Connector()\n",
    "        \n",
    "    # we need Vector Assambler here anyway\n",
    "    assemble_numeric = VectorAssembler(inputCols=num_cols,outputCol='numeric_features')\n",
    "    \n",
    "    # if we need normalizer\n",
    "    if normalize:\n",
    "        normalizer = Normalizer(inputCol='numeric_features',outputCol='numeric_features1')\n",
    "        column_handler1 = ColumnHandler(delete_col='numeric_features',replace_col='numeric_features1')\n",
    "    else:\n",
    "        normalizer = Connector()\n",
    "        column_handler1 = Connector()\n",
    "    \n",
    "    # standard scaller\n",
    "    if standard_scale:\n",
    "        standard_scaler = StandardScaler(inputCol='numeric_features',outputCol='numeric_features1',\n",
    "                                        withMean=standard_scaler_withMean,withStd=standard_scaler_withStd)\n",
    "        column_handler2 = ColumnHandler(delete_col='numeric_features',replace_col='numeric_features1')\n",
    "    else:\n",
    "        standard_scaler = Connector()\n",
    "        column_handler2 = Connector()\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    \n",
    "    \n",
    "    p = Pipeline(stages=[imputer,assemble_numeric,normalizer,column_handler1,standard_scaler,column_handler2])\n",
    "    \n",
    "    return p\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bcb837cd-a493-4879-bdb2-d1f85fc8eb94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---+---------+--------+---+-------+--------+----------------+--------------------+\n",
      "|LIMIT_BAL|SEX|EDUCATION|MARRIAGE|AGE|BAL_CAT|maturity|numeric_features|    numeric_features|\n",
      "+---------+---+---------+--------+---+-------+--------+----------------+--------------------+\n",
      "|    20000|  2|        2|       1| 24|    low|   youth|      [24.0,2.0]|[0.99654575824487...|\n",
      "|    90000|  2|        2|       2| 34|    low|    yong|      [34.0,2.0]|[0.99827437317499...|\n",
      "|    50000|  2|        2|       1| 37|    low|    yong|      [37.0,2.0]|[0.99854227327750...|\n",
      "|    50000|  1|        2|       1| 57|    low|  mature|      [57.0,1.0]|[0.99984614201001...|\n",
      "|    50000|  1|        1|       2| 37|    low|    yong|      [37.0,1.0]|[0.99963496987285...|\n",
      "|   100000|  2|        2|       2| 23| medium|   youth|      [23.0,2.0]|[0.99624058819568...|\n",
      "|   140000|  2|        3|       1| 28| medium|   youth|      [28.0,2.0]|[0.99745869983073...|\n",
      "|    20000|  1|        3|       2| 35|    low|    yong|      [35.0,1.0]|[0.99959208646069...|\n",
      "|   200000|  2|        3|       2| 34| medium|    yong|      [34.0,2.0]|[0.99827437317499...|\n",
      "|   260000|  2|        1|       2| 51|   high|  mature|      [51.0,2.0]|[0.99923195073154...|\n",
      "|   630000|  2|        2|       2| 41|   high|  mature|      [41.0,2.0]|[0.99881235112489...|\n",
      "|   250000|  1|        1|       2| 29|   high|   youth|      [29.0,1.0]|[0.99940599935358...|\n",
      "|    50000|  2|        3|       3| 23|    low|   youth|      [23.0,2.0]|[0.99624058819568...|\n",
      "|    20000|  1|        1|       2| 24|    low|   youth|      [24.0,1.0]|[0.99913307309235...|\n",
      "|   320000|  1|        1|       1| 49|   high|  mature|      [49.0,1.0]|[0.99979181846344...|\n",
      "|   360000|  2|        1|       1| 49|   high|  mature|      [49.0,2.0]|[0.99916805310057...|\n",
      "|   180000|  2|        1|       2| 29| medium|   youth|      [29.0,2.0]|[0.99763032842298...|\n",
      "|   130000|  2|        3|       2| 39| medium|    yong|      [39.0,2.0]|[0.99868766347658...|\n",
      "|    70000|  2|        2|       2| 26|    low|   youth|      [26.0,2.0]|[0.99705448550158...|\n",
      "|   450000|  2|        1|       1| 40|   high|    yong|      [40.0,2.0]|[0.99875233887784...|\n",
      "+---------+---+---------+--------+---+-------+--------+----------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# imp = Imputer(inputCols=['AGE','SEX'],outputCols=['AGE','SEX'])\n",
    "# assmb = VectorAssembler(inputCols=['AGE','SEX'],outputCol='features')\n",
    "# norm = nnormalizer()\n",
    "# # assmb2 = VectorAssembler(inputCols=['features1'],outputCol='features2')\n",
    "# pipe = Pipeline(stages = [imp])\n",
    "\n",
    "\n",
    "pipe = _pipe(num_cols=['AGE','SEX'],cat_cols=None,impute=False,impute_strategy='mean',normalize=True,normalize_p=2,standard_scale=False)\n",
    "fitted = pipe.fit(spark_df)\n",
    "fitted.transform(spark_df).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "194a624b-c8ad-47ba-b1ef-0799e5386d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Preprocessor(training_data=train\n",
    "                     ,hold_out_data=test,\n",
    "                     target_feature='LIMIT_BAL',\n",
    "                     numeric_features= ['AGE','SEX'],\n",
    "                     categorical_features=[\"BAL_CAT\",\"maturity\"],\n",
    "                     impute_missing_values=True, missing_value_strategy=\"mean\",\n",
    "                     normalize= True,\n",
    "                     standard_scale=True,\n",
    "                    \n",
    "                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "11fabe40-3740-4d42-98d6-8e503db6faf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.run_pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "2f982626",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.fit_transform()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "9bb44cb0-6dc0-4109-87bc-50f1d1506c15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---+---------+--------+---+-------+--------+--------------------+--------------------+\n",
      "|LIMIT_BAL|SEX|EDUCATION|MARRIAGE|AGE|BAL_CAT|maturity|    numeric_features|categorical_features|\n",
      "+---------+---+---------+--------+---+-------+--------+--------------------+--------------------+\n",
      "|  10000.0|  1|        1|       1| 38|    low|    yong|[954.733573425178...| (6,[0,3],[1.0,1.0])|\n",
      "|  10000.0|  1|        1|       1| 40|    low|    yong|[954.765784924959...| (6,[0,3],[1.0,1.0])|\n",
      "|  10000.0|  1|        1|       1| 48|    low|  mature|[954.856907896601...| (6,[0,5],[1.0,1.0])|\n",
      "|  10000.0|  1|        1|       1| 50|    low|  mature|[954.873147092114...| (6,[0,5],[1.0,1.0])|\n",
      "|  10000.0|  1|        1|       2| 22|    low|   youth|[954.078992409441...| (6,[0,4],[1.0,1.0])|\n",
      "|  10000.0|  1|        1|       2| 22|    low|   youth|[954.078992409441...| (6,[0,4],[1.0,1.0])|\n",
      "|  10000.0|  1|        1|       2| 23|    low|   youth|[954.162673354240...| (6,[0,4],[1.0,1.0])|\n",
      "|  10000.0|  1|        1|       2| 23|    low|   youth|[954.162673354240...| (6,[0,4],[1.0,1.0])|\n",
      "|  10000.0|  1|        1|       2| 23|    low|   youth|[954.162673354240...| (6,[0,4],[1.0,1.0])|\n",
      "|  10000.0|  1|        1|       2| 23|    low|   youth|[954.162673354240...| (6,[0,4],[1.0,1.0])|\n",
      "|  10000.0|  1|        1|       2| 24|    low|   youth|[954.236131858791...| (6,[0,4],[1.0,1.0])|\n",
      "|  10000.0|  1|        1|       2| 24|    low|   youth|[954.236131858791...| (6,[0,4],[1.0,1.0])|\n",
      "|  10000.0|  1|        1|       2| 24|    low|   youth|[954.236131858791...| (6,[0,4],[1.0,1.0])|\n",
      "|  10000.0|  1|        1|       2| 24|    low|   youth|[954.236131858791...| (6,[0,4],[1.0,1.0])|\n",
      "|  10000.0|  1|        1|       2| 25|    low|   youth|[954.300966986551...| (6,[0,4],[1.0,1.0])|\n",
      "|  10000.0|  1|        1|       2| 25|    low|   youth|[954.300966986551...| (6,[0,4],[1.0,1.0])|\n",
      "|  10000.0|  1|        1|       2| 25|    low|   youth|[954.300966986551...| (6,[0,4],[1.0,1.0])|\n",
      "|  10000.0|  1|        1|       2| 26|    low|   youth|[954.358477040145...| (6,[0,4],[1.0,1.0])|\n",
      "|  10000.0|  1|        1|       2| 27|    low|   youth|[954.409724954194...| (6,[0,4],[1.0,1.0])|\n",
      "|  10000.0|  1|        1|       2| 29|    low|   youth|[954.496793933561...| (6,[0,4],[1.0,1.0])|\n",
      "+---------+---+---------+--------+---+-------+--------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pipe.train_data_transformed.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "f32ae307-91fb-4fb8-bedf-921c6be4fc6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---+---------+--------+---+-------+--------+--------------------+--------------------+--------------------+--------------------+\n",
      "|LIMIT_BAL|SEX|EDUCATION|MARRIAGE|AGE|BAL_CAT|maturity|    numeric_features|categorical_features|                 int|               final|\n",
      "+---------+---+---------+--------+---+-------+--------+--------------------+--------------------+--------------------+--------------------+\n",
      "|  10000.0|  1|        1|       1| 38|    low|    yong|[954.733573425178...| (6,[0,3],[1.0,1.0])|(6,[0,3],[38.0,38...|(8,[0,1,2,5],[954...|\n",
      "|  10000.0|  1|        1|       1| 40|    low|    yong|[954.765784924959...| (6,[0,3],[1.0,1.0])|(6,[0,3],[40.0,40...|(8,[0,1,2,5],[954...|\n",
      "|  10000.0|  1|        1|       1| 48|    low|  mature|[954.856907896601...| (6,[0,5],[1.0,1.0])|(6,[0,5],[48.0,48...|(8,[0,1,2,7],[954...|\n",
      "|  10000.0|  1|        1|       1| 50|    low|  mature|[954.873147092114...| (6,[0,5],[1.0,1.0])|(6,[0,5],[50.0,50...|(8,[0,1,2,7],[954...|\n",
      "|  10000.0|  1|        1|       2| 22|    low|   youth|[954.078992409441...| (6,[0,4],[1.0,1.0])|(6,[0,4],[44.0,44...|(8,[0,1,2,6],[954...|\n",
      "|  10000.0|  1|        1|       2| 22|    low|   youth|[954.078992409441...| (6,[0,4],[1.0,1.0])|(6,[0,4],[44.0,44...|(8,[0,1,2,6],[954...|\n",
      "|  10000.0|  1|        1|       2| 23|    low|   youth|[954.162673354240...| (6,[0,4],[1.0,1.0])|(6,[0,4],[46.0,46...|(8,[0,1,2,6],[954...|\n",
      "|  10000.0|  1|        1|       2| 23|    low|   youth|[954.162673354240...| (6,[0,4],[1.0,1.0])|(6,[0,4],[46.0,46...|(8,[0,1,2,6],[954...|\n",
      "|  10000.0|  1|        1|       2| 23|    low|   youth|[954.162673354240...| (6,[0,4],[1.0,1.0])|(6,[0,4],[46.0,46...|(8,[0,1,2,6],[954...|\n",
      "|  10000.0|  1|        1|       2| 23|    low|   youth|[954.162673354240...| (6,[0,4],[1.0,1.0])|(6,[0,4],[46.0,46...|(8,[0,1,2,6],[954...|\n",
      "|  10000.0|  1|        1|       2| 24|    low|   youth|[954.236131858791...| (6,[0,4],[1.0,1.0])|(6,[0,4],[48.0,48...|(8,[0,1,2,6],[954...|\n",
      "|  10000.0|  1|        1|       2| 24|    low|   youth|[954.236131858791...| (6,[0,4],[1.0,1.0])|(6,[0,4],[48.0,48...|(8,[0,1,2,6],[954...|\n",
      "|  10000.0|  1|        1|       2| 24|    low|   youth|[954.236131858791...| (6,[0,4],[1.0,1.0])|(6,[0,4],[48.0,48...|(8,[0,1,2,6],[954...|\n",
      "|  10000.0|  1|        1|       2| 24|    low|   youth|[954.236131858791...| (6,[0,4],[1.0,1.0])|(6,[0,4],[48.0,48...|(8,[0,1,2,6],[954...|\n",
      "|  10000.0|  1|        1|       2| 25|    low|   youth|[954.300966986551...| (6,[0,4],[1.0,1.0])|(6,[0,4],[50.0,50...|(8,[0,1,2,6],[954...|\n",
      "|  10000.0|  1|        1|       2| 25|    low|   youth|[954.300966986551...| (6,[0,4],[1.0,1.0])|(6,[0,4],[50.0,50...|(8,[0,1,2,6],[954...|\n",
      "|  10000.0|  1|        1|       2| 25|    low|   youth|[954.300966986551...| (6,[0,4],[1.0,1.0])|(6,[0,4],[50.0,50...|(8,[0,1,2,6],[954...|\n",
      "|  10000.0|  1|        1|       2| 26|    low|   youth|[954.358477040145...| (6,[0,4],[1.0,1.0])|(6,[0,4],[52.0,52...|(8,[0,1,2,6],[954...|\n",
      "|  10000.0|  1|        1|       2| 27|    low|   youth|[954.409724954194...| (6,[0,4],[1.0,1.0])|(6,[0,4],[54.0,54...|(8,[0,1,2,6],[954...|\n",
      "|  10000.0|  1|        1|       2| 29|    low|   youth|[954.496793933561...| (6,[0,4],[1.0,1.0])|(6,[0,4],[58.0,58...|(8,[0,1,2,6],[954...|\n",
      "+---------+---+---------+--------+---+-------+--------+--------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import Interaction \n",
    "_int = Interaction(inputCols=['categorical_features','AGE','MARRIAGE',],outputCol='int')\n",
    "df1 = _int.transform(pipe.train_data_transformed)\n",
    "\n",
    "# how to do it ?\n",
    "# if all numeric columns\n",
    "#  pass all numeric features (one by one)\n",
    "\n",
    "# if all categorical\n",
    "# pass all encoded features one by one\n",
    "\n",
    "# if numeric and categorical\n",
    " # pass categorical assembled feature with numeric features (one by one)\n",
    "# take all the numeric features (if any) and IF Categorical features are there use the onehotencoded with vector assembler\n",
    "\n",
    "# UPDATE: in any/all cases, we need encoded features forcategorical , and numeric features as is (both one by one)\n",
    "\n",
    "ass = VectorAssembler(inputCols=['numeric_features','int'],outputCol='final')\n",
    "df1 = ass.transform(df1)\n",
    "df1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "ebfda353",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---+---+---+---------+------------+-------------+-------------+\n",
      "| name|  a|  b|  f|a_indexed|name_indexed|    a_encoded| name_encoded|\n",
      "+-----+---+---+---+---------+------------+-------------+-------------+\n",
      "|fahad|  c|2.0|4.0|      0.0|         0.0|(1,[0],[1.0])|(2,[0],[1.0])|\n",
      "|umair|  c|3.0|5.0|      0.0|         1.0|(1,[0],[1.0])|(2,[1],[1.0])|\n",
      "+-----+---+---+---+---------+------------+-------------+-------------+\n",
      "\n",
      "+-----+---+---+---+---------+------------+-------------+-------------+-------------+\n",
      "| name|  a|  b|  f|a_indexed|name_indexed|    a_encoded| name_encoded|     features|\n",
      "+-----+---+---+---+---------+------------+-------------+-------------+-------------+\n",
      "|fahad|  c|2.0|4.0|      0.0|         0.0|(1,[0],[1.0])|(2,[0],[1.0])|[1.0,1.0,0.0]|\n",
      "|umair|  c|3.0|5.0|      0.0|         1.0|(1,[0],[1.0])|(2,[1],[1.0])|[1.0,0.0,1.0]|\n",
      "+-----+---+---+---+---------+------------+-------------+-------------+-------------+\n",
      "\n",
      "+-----+---+---+---+---------+------------+-------------+-------------+-------------+--------------+\n",
      "| name|  a|  b|  f|a_indexed|name_indexed|    a_encoded| name_encoded|     features|features_inter|\n",
      "+-----+---+---+---+---------+------------+-------------+-------------+-------------+--------------+\n",
      "|fahad|  c|2.0|4.0|      0.0|         0.0|(1,[0],[1.0])|(2,[0],[1.0])|[1.0,1.0,0.0]|     [1.0,0.0]|\n",
      "|umair|  c|3.0|5.0|      0.0|         1.0|(1,[0],[1.0])|(2,[1],[1.0])|[1.0,0.0,1.0]|     [0.0,1.0]|\n",
      "+-----+---+---+---+---------+------------+-------------+-------------+-------------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df =  ps.DataFrame([(\"fahad\",\"c\", 2.0,4.0), (\"umair\",\"c\", 3.0,5.0)], columns =[\"name\",\"a\", \"b\",'f']).to_spark()\n",
    "\n",
    "ind = StringIndexer(inputCols=['a','name'],outputCols=['a_indexed','name_indexed'])\n",
    "df = ind.fit(df).transform(df)\n",
    "enc = OneHotEncoder(inputCols=[\"a_indexed\",\"name_indexed\"],outputCols=['a_encoded',\"name_encoded\"],dropLast=False)\n",
    "df = enc.fit(df).transform(df)\n",
    "df.show()\n",
    "\n",
    "# interaction = Interaction()\n",
    "# interaction.setInputCols([\"encoded\", \"b\",\"f\"])\n",
    "\n",
    "# interaction.setOutputCol(\"interacted\")\n",
    "\n",
    "# df = interaction.transform(df)\n",
    "\n",
    "# df.show()\n",
    "\n",
    "ass = VectorAssembler(inputCols=['a_encoded','name_encoded'],outputCol='features')\n",
    "df = ass.transform(df)\n",
    "df.show()\n",
    "\n",
    "_in = Interaction(inputCols=[\"a_encoded\",\"name_encoded\"],outputCol='features_inter')\n",
    "_in.transform(df).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "both are not none\n"
     ]
    }
   ],
   "source": [
    "num = ['num1','num2']\n",
    "cat = ['a']\n",
    "\n",
    "do_it = True\n",
    "\n",
    "if (do_it and cat):\n",
    "    print(\"both are not none\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "567722a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['num1', 'cat2_indexer']"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce4d3bbe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "32692823d3109f5bd75447dae6e1c6d928fc2410e760df9aa7f12324a979215b"
  },
  "kernelspec": {
   "display_name": "Python [conda env:SparkAutoML] *",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
