{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e2b7568-a569-48be-89ec-28bd003dd61e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:'PYARROW_IGNORE_TIMEZONE' environment variable was not set. It is required to set this environment variable to '1' in both driver and executor sides if you use pyarrow>=2.0.0. pandas-on-Spark will set it for you but it does not work if there is a Spark context already launched.\n"
     ]
    }
   ],
   "source": [
    "from typing import List\n",
    "# from databricks import koalas as ks , we do not neven need koalsa, because it is now built in with databricks\n",
    "import pyspark.pandas as ps\n",
    "from pyspark.sql import DataFrame as SparkDataFrame\n",
    "\n",
    "from pyspark.ml.feature import VectorAssembler,VectorIndexer,OneHotEncoder,StringIndexer\n",
    "from pyspark.ml import Pipeline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b318cebc-02af-412b-9ad4-7d1bc7842d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pyspark import keyword_only  ## < 2.0 -> pyspark.ml.util.keyword_only\n",
    "from pyspark.ml import Transformer\n",
    "from pyspark.ml.param.shared import HasInputCol, HasOutputCol, Param, Params, TypeConverters\n",
    "# Available in PySpark >= 2.3.0 \n",
    "from pyspark.ml.util import DefaultParamsReadable, DefaultParamsWritable  \n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import ArrayType, StringType\n",
    "\n",
    "class Connector(\n",
    "        Transformer, HasInputCol, HasOutputCol,\n",
    "        # Credits https://stackoverflow.com/a/52467470\n",
    "        # by https://stackoverflow.com/users/234944/benjamin-manns\n",
    "        DefaultParamsReadable, DefaultParamsWritable):\n",
    "\n",
    "\n",
    "    @keyword_only\n",
    "    def __init__(self, inputCol=None, outputCol=None):\n",
    "        super(Connector, self).__init__()\n",
    "        kwargs = self._input_kwargs\n",
    "        self.setParams(**kwargs)\n",
    "\n",
    "    @keyword_only\n",
    "    def setParams(self, inputCol=None, outputCol=None,):\n",
    "        kwargs = self._input_kwargs\n",
    "        return self._set(**kwargs)\n",
    "\n",
    "\n",
    "    # Required in Spark >= 3.0\n",
    "    def setInputCol(self, value):\n",
    "        \"\"\"\n",
    "        Sets the value of :py:attr:`inputCol`.\n",
    "        \"\"\"\n",
    "        return self._set(inputCol=value)\n",
    "\n",
    "    # Required in Spark >= 3.0\n",
    "    def setOutputCol(self, value):\n",
    "        \"\"\"\n",
    "        Sets the value of :py:attr:`outputCol`.\n",
    "        \"\"\"\n",
    "        return self._set(outputCol=value)\n",
    "\n",
    "    def _transform(self, dataset):\n",
    "        dataset = dataset\n",
    "\n",
    "        return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "27349345-5ca4-4e07-a159-e0a53e790118",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pyspark import keyword_only  ## < 2.0 -> pyspark.ml.util.keyword_only\n",
    "from pyspark.ml import Transformer\n",
    "from pyspark.ml.param.shared import HasInputCol, HasOutputCol, Param, Params, TypeConverters\n",
    "# Available in PySpark >= 2.3.0 \n",
    "from pyspark.ml.util import DefaultParamsReadable, DefaultParamsWritable  \n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import ArrayType, StringType\n",
    "\n",
    "class ColumnHandler(\n",
    "        Transformer, HasInputCol, HasOutputCol,\n",
    "        DefaultParamsReadable, DefaultParamsWritable):\n",
    "    \n",
    "    delete_col = Param(Params._dummy(), \"delete_col\", \"delete_col\",\n",
    "                      typeConverter=TypeConverters.toString)\n",
    "    \n",
    "    replace_col = Param(Params._dummy(), \"replace_col\", \"replace_col\",\n",
    "                      typeConverter=TypeConverters.toString)\n",
    "\n",
    "\n",
    "    @keyword_only\n",
    "    def __init__(self, inputCol=None, outputCol=None,delete_col=None,replace_col=None):\n",
    "        super(ColumnHandler, self).__init__()\n",
    "        self.delete_col = Param(self, \"delete_col\", \"\")\n",
    "        self.replace_col = Param(self, \"replace_col\", \"\")\n",
    "        kwargs = self._input_kwargs\n",
    "        self.setParams(**kwargs)\n",
    "\n",
    "    @keyword_only\n",
    "    def setParams(self, inputCol=None, outputCol=None,delete_col=None,replace_col=None):\n",
    "        kwargs = self._input_kwargs\n",
    "        return self._set(**kwargs)\n",
    "    \n",
    "    def setDeleteCol(self, value):\n",
    "        return self._set(delete_col=value)\n",
    "\n",
    "    def getDeleteCol(self):\n",
    "        return self.getOrDefault(self.delete_col)\n",
    "    \n",
    "        \n",
    "    def setReplaceCol(self, value):\n",
    "        return self._set(replace_col=value)\n",
    "\n",
    "    def getReplaceCol(self):\n",
    "        return self.getOrDefault(self.replace_col)\n",
    "\n",
    "\n",
    "    # Required in Spark >= 3.0\n",
    "    def setInputCol(self, value):\n",
    "        \"\"\"\n",
    "        Sets the value of :py:attr:`inputCol`.\n",
    "        \"\"\"\n",
    "        return self._set(inputCol=value)\n",
    "\n",
    "    # Required in Spark >= 3.0\n",
    "    def setOutputCol(self, value):\n",
    "        \"\"\"\n",
    "        Sets the value of :py:attr:`outputCol`.\n",
    "        \"\"\"\n",
    "        return self._set(outputCol=value)\n",
    "\n",
    "    def _transform(self, dataset):\n",
    "        delete_col = self.getDeleteCol()\n",
    "        replace_col = self.getReplaceCol()\n",
    "        \n",
    "        dataset = dataset.drop(*delete_col) \n",
    "        dataset = dataset.withColumnRenamed(replace_col,delete_col) \n",
    "\n",
    "        return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ec713d48-371d-4b3e-930d-956e4378299b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pyspark import keyword_only  ## < 2.0 -> pyspark.ml.util.keyword_only\n",
    "from pyspark.ml import Transformer\n",
    "from pyspark.ml.param.shared import HasInputCol, HasOutputCol, Param, Params, TypeConverters\n",
    "# Available in PySpark >= 2.3.0 \n",
    "from pyspark.ml.util import DefaultParamsReadable, DefaultParamsWritable  \n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import ArrayType, StringType\n",
    "\n",
    "class Custom_OneHotEncoder(\n",
    "        Transformer, HasInputCol, HasOutputCol,\n",
    "        DefaultParamsReadable, DefaultParamsWritable):\n",
    "    \n",
    "    input_columns = Param(Params._dummy(), \"input_columns\", \"input_columns\",\n",
    "                      typeConverter=TypeConverters.toListString)\n",
    "    \n",
    "    output_column = Param(Params._dummy(), \"output_column\", \"output_column\",\n",
    "                      typeConverter=TypeConverters.toString)\n",
    "\n",
    "\n",
    "    @keyword_only\n",
    "    def __init__(self, inputCol=None, outputCol=None,input_columns=None,output_column=None):\n",
    "        super(Custom_OneHotEncoder, self).__init__()\n",
    "        self.input_columns = Param(self, \"input_columns\", \"\")\n",
    "        self.output_column = Param(self, \"output_column\", \"\")\n",
    "        kwargs = self._input_kwargs\n",
    "        self.setParams(**kwargs)\n",
    "\n",
    "    @keyword_only\n",
    "    def setParams(self, inputCol=None, outputCol=None,input_columns=None,output_column=None):\n",
    "        kwargs = self._input_kwargs\n",
    "        return self._set(**kwargs)\n",
    "    \n",
    "    def setInput_columns(self, value):\n",
    "        return self._set(input_columns=value)\n",
    "\n",
    "    def getInput_columns(self):\n",
    "        return self.getOrDefault(self.input_columns)\n",
    "    \n",
    "        \n",
    "    def setOutput_column(self, value):\n",
    "        return self._set(output_column=value)\n",
    "\n",
    "    def getOutput_column(self):\n",
    "        return self.getOrDefault(self.output_column)\n",
    "\n",
    "\n",
    "    # Required in Spark >= 3.0\n",
    "    def setInputCol(self, value):\n",
    "        \"\"\"\n",
    "        Sets the value of :py:attr:`inputCol`.\n",
    "        \"\"\"\n",
    "        return self._set(inputCol=value)\n",
    "\n",
    "    # Required in Spark >= 3.0\n",
    "    def setOutputCol(self, value):\n",
    "        \"\"\"\n",
    "        Sets the value of :py:attr:`outputCol`.\n",
    "        \"\"\"\n",
    "        return self._set(outputCol=value)\n",
    "\n",
    "    def _transform(self, dataset):\n",
    "        \n",
    "        input_cols = self.getInput_columns()\n",
    "        output_col = self.getOutput_column()\n",
    "        \n",
    "        indexer = StringIndexer(inputCols=input_cols,outputCols= [column + str(\"_indexer\") for column in input_cols])\n",
    "        encoder = OneHotEncoder(inputCols=[column + str(\"_indexer\") for column in input_cols] , outputCols= \n",
    "                                [column + str(\"_encoded\") for column in input_cols], dropLast=False)\n",
    "        assembler = VectorAssembler(inputCols= [column + str(\"_encoded\") for column in input_cols],\n",
    "                                    outputCol= output_col)\n",
    "        \n",
    "        \n",
    "\n",
    "        return indexer,encoder,assembler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b8ed131-f16c-43a9-ba98-355454cddc45",
   "metadata": {},
   "outputs": [],
   "source": [
    "from SparkAutoML.ml_module.preprocessing_module.preprocess_file import Preprocessor\n",
    "from pyspark.sql.types import FloatType\n",
    "from pyspark.sql.types import IntegerType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e07e151a-dcae-454b-9809-18a2322c8430",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data \n",
    "df = ps.read_csv(\"credit.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1eca9b8b-5dbd-4cd8-b961-71f8c6284cab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['LIMIT_BAL', 'SEX', 'EDUCATION', 'MARRIAGE', 'AGE', 'PAY_1', 'PAY_2',\n",
       "       'PAY_3', 'PAY_4', 'PAY_5', 'PAY_6', 'BILL_AMT1', 'BILL_AMT2',\n",
       "       'BILL_AMT3', 'BILL_AMT4', 'BILL_AMT5', 'BILL_AMT6', 'PAY_AMT1',\n",
       "       'PAY_AMT2', 'PAY_AMT3', 'PAY_AMT4', 'PAY_AMT5', 'PAY_AMT6', 'default'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cd56852e-d2e5-462c-b991-91a8fcd1c0f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#def bool_function(df:ks.DataFrame)->ks.DataFrame:\n",
    "def bool_function(df):\n",
    "  df =ps.sql(\"\"\"select *,\n",
    "  case when mean_bal > 50000 then 1 else 0 end as new_bol_sql\n",
    "  from {df}\"\"\")\n",
    "  return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "48b59b38-7b1a-4b74-a45f-dbee2d5a8842",
   "metadata": {},
   "outputs": [],
   "source": [
    "# that is how you can apply the full stack piping in koalas\n",
    "df= (\n",
    "df\n",
    "[['LIMIT_BAL', 'SEX', 'EDUCATION', 'MARRIAGE', 'AGE']]\n",
    ".pipe(lambda x: ps.sql(\"\"\" select * , case when LIMIT_BAL < 100000 then 'low' when LIMIT_BAL between 100000 and 200000 then 'medium' else 'high' end as BAL_CAT from {x}\"\"\"))\n",
    ".pipe(lambda x: ps.sql(\"\"\" select * , case when AGE < 30 then 'youth' when AGE between 30 and 40 then 'yong' else 'mature' end as maturity from {x}\"\"\"))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c93721e1-b45c-4706-9857-6dd73ef61429",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LIMIT_BAL</th>\n",
       "      <th>SEX</th>\n",
       "      <th>EDUCATION</th>\n",
       "      <th>MARRIAGE</th>\n",
       "      <th>AGE</th>\n",
       "      <th>BAL_CAT</th>\n",
       "      <th>maturity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>low</td>\n",
       "      <td>youth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>90000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>34</td>\n",
       "      <td>low</td>\n",
       "      <td>yong</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>low</td>\n",
       "      <td>yong</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>57</td>\n",
       "      <td>low</td>\n",
       "      <td>mature</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>37</td>\n",
       "      <td>low</td>\n",
       "      <td>yong</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   LIMIT_BAL  SEX  EDUCATION  MARRIAGE  AGE BAL_CAT maturity\n",
       "0      20000    2          2         1   24     low    youth\n",
       "1      90000    2          2         2   34     low     yong\n",
       "2      50000    2          2         1   37     low     yong\n",
       "3      50000    1          2         1   57     low   mature\n",
       "4      50000    1          1         2   37     low     yong"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c0194fe0-fa84-429d-856c-ee6a20571dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import (\n",
    "    VectorAssembler,\n",
    "    VectorIndexer,\n",
    "    OneHotEncoder,\n",
    "    StringIndexer,\n",
    "    Imputer,\n",
    "    Normalizer,\n",
    "    StandardScaler,\n",
    ")\n",
    "from pyspark.ml import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ba43d31e-11f2-449f-b700-2a274f005b65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler_3e9ad9ef8f3f"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "145e0d8c-a169-4236-98b4-ea2f224681e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# df.iloc[0,4] = np.nan\n",
    "# df.AGE = df.AGE.astype(float)\n",
    "spark_df = df.to_spark()\n",
    "# spark_df = spark_df.withColumn('AGE', spark_df['AGE'].cast(IntegerType()))\n",
    "train,test = spark_df.randomSplit([.70,.30],seed=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "80d334d4-53c1-4a1f-9c67-37de43693fa5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['LIMIT_BAL', 'SEX', 'EDUCATION', 'MARRIAGE', 'AGE', 'BAL_CAT', 'maturity']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a4c81f2f-58e2-4ebc-967f-e20de8fa4443",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _pipe(num_cols,cat_cols=None, impute=False, impute_strategy='mean', normalize=False, normalize_p=2, \n",
    "          standard_scale =False,standard_scaler_withMean=False,standard_scaler_withStd=True,):\n",
    "    \n",
    "    # first we deploy imputer\n",
    "    if impute:\n",
    "        imputer = Imputer(inputCols=num_cols,outputCols=num_cols,strategy=impute_strategy)\n",
    "    else:\n",
    "        imputer = Connector()\n",
    "        \n",
    "    # we need Vector Assambler here anyway\n",
    "    assemble_numeric = VectorAssembler(inputCols=num_cols,outputCol='numeric_features')\n",
    "    \n",
    "    # if we need normalizer\n",
    "    if normalize:\n",
    "        normalizer = Normalizer(inputCol='numeric_features',outputCol='numeric_features1')\n",
    "        column_handler1 = ColumnHandler(delete_col='numeric_features',replace_col='numeric_features1')\n",
    "    else:\n",
    "        normalizer = Connector()\n",
    "        column_handler1 = Connector()\n",
    "    \n",
    "    # standard scaller\n",
    "    if standard_scale:\n",
    "        standard_scaler = StandardScaler(inputCol='numeric_features',outputCol='numeric_features1',\n",
    "                                        withMean=standard_scaler_withMean,withStd=standard_scaler_withStd)\n",
    "        column_handler2 = ColumnHandler(delete_col='numeric_features',replace_col='numeric_features1')\n",
    "    else:\n",
    "        standard_scaler = Connector()\n",
    "        column_handler2 = Connector()\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    \n",
    "    \n",
    "    p = Pipeline(stages=[imputer,assemble_numeric,normalizer,column_handler1,standard_scaler,column_handler2])\n",
    "    \n",
    "    return p\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bcb837cd-a493-4879-bdb2-d1f85fc8eb94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---+---------+--------+---+-------+--------+--------------------+\n",
      "|LIMIT_BAL|SEX|EDUCATION|MARRIAGE|AGE|BAL_CAT|maturity|    numeric_features|\n",
      "+---------+---+---------+--------+---+-------+--------+--------------------+\n",
      "|    20000|  2|        2|       1| 24|    low|   youth|[0.99654575824487...|\n",
      "|    90000|  2|        2|       2| 34|    low|    yong|[0.99827437317499...|\n",
      "|    50000|  2|        2|       1| 37|    low|    yong|[0.99854227327750...|\n",
      "|    50000|  1|        2|       1| 57|    low|  mature|[0.99984614201001...|\n",
      "|    50000|  1|        1|       2| 37|    low|    yong|[0.99963496987285...|\n",
      "|   100000|  2|        2|       2| 23| medium|   youth|[0.99624058819568...|\n",
      "|   140000|  2|        3|       1| 28| medium|   youth|[0.99745869983073...|\n",
      "|    20000|  1|        3|       2| 35|    low|    yong|[0.99959208646069...|\n",
      "|   200000|  2|        3|       2| 34| medium|    yong|[0.99827437317499...|\n",
      "|   260000|  2|        1|       2| 51|   high|  mature|[0.99923195073154...|\n",
      "|   630000|  2|        2|       2| 41|   high|  mature|[0.99881235112489...|\n",
      "|   250000|  1|        1|       2| 29|   high|   youth|[0.99940599935358...|\n",
      "|    50000|  2|        3|       3| 23|    low|   youth|[0.99624058819568...|\n",
      "|    20000|  1|        1|       2| 24|    low|   youth|[0.99913307309235...|\n",
      "|   320000|  1|        1|       1| 49|   high|  mature|[0.99979181846344...|\n",
      "|   360000|  2|        1|       1| 49|   high|  mature|[0.99916805310057...|\n",
      "|   180000|  2|        1|       2| 29| medium|   youth|[0.99763032842298...|\n",
      "|   130000|  2|        3|       2| 39| medium|    yong|[0.99868766347658...|\n",
      "|    70000|  2|        2|       2| 26|    low|   youth|[0.99705448550158...|\n",
      "|   450000|  2|        1|       1| 40|   high|    yong|[0.99875233887784...|\n",
      "+---------+---+---------+--------+---+-------+--------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# imp = Imputer(inputCols=['AGE','SEX'],outputCols=['AGE','SEX'])\n",
    "# assmb = VectorAssembler(inputCols=['AGE','SEX'],outputCol='features')\n",
    "# norm = nnormalizer()\n",
    "# # assmb2 = VectorAssembler(inputCols=['features1'],outputCol='features2')\n",
    "# pipe = Pipeline(stages = [imp])\n",
    "\n",
    "\n",
    "pipe = _pipe(num_cols=['AGE','SEX'],cat_cols=None,impute=False,impute_strategy='mean',normalize=True,normalize_p=2,standard_scale=False)\n",
    "fitted = pipe.fit(spark_df)\n",
    "fitted.transform(spark_df).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "194a624b-c8ad-47ba-b1ef-0799e5386d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Preprocessor(training_data=train\n",
    "                     ,hold_out_data=test,\n",
    "                     target_feature='LIMIT_BAL',\n",
    "                     numeric_features= ['AGE','SEX'],\n",
    "                     categorical_features=[\"BAL_CAT\",\"maturity\"],\n",
    "                     impute_missing_values=True, missing_value_strategy=\"mean\",\n",
    "                     normalize= True,\n",
    "                     standard_scale=True\n",
    "                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "11fabe40-3740-4d42-98d6-8e503db6faf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.run_pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2f982626",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.fit_transform()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9bb44cb0-6dc0-4109-87bc-50f1d1506c15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---+---------+--------+---+-------+--------+--------------------+\n",
      "|LIMIT_BAL|SEX|EDUCATION|MARRIAGE|AGE|BAL_CAT|maturity|    numeric_features|\n",
      "+---------+---+---------+--------+---+-------+--------+--------------------+\n",
      "|  10000.0|  1|        1|       1| 38|    low|    yong|[954.733573425178...|\n",
      "|  10000.0|  1|        1|       1| 40|    low|    yong|[954.765784924959...|\n",
      "|  10000.0|  1|        1|       1| 48|    low|  mature|[954.856907896601...|\n",
      "|  10000.0|  1|        1|       1| 50|    low|  mature|[954.873147092114...|\n",
      "|  10000.0|  1|        1|       2| 22|    low|   youth|[954.078992409441...|\n",
      "|  10000.0|  1|        1|       2| 22|    low|   youth|[954.078992409441...|\n",
      "|  10000.0|  1|        1|       2| 23|    low|   youth|[954.162673354240...|\n",
      "|  10000.0|  1|        1|       2| 23|    low|   youth|[954.162673354240...|\n",
      "|  10000.0|  1|        1|       2| 23|    low|   youth|[954.162673354240...|\n",
      "|  10000.0|  1|        1|       2| 23|    low|   youth|[954.162673354240...|\n",
      "|  10000.0|  1|        1|       2| 24|    low|   youth|[954.236131858791...|\n",
      "|  10000.0|  1|        1|       2| 24|    low|   youth|[954.236131858791...|\n",
      "|  10000.0|  1|        1|       2| 24|    low|   youth|[954.236131858791...|\n",
      "|  10000.0|  1|        1|       2| 24|    low|   youth|[954.236131858791...|\n",
      "|  10000.0|  1|        1|       2| 25|    low|   youth|[954.300966986551...|\n",
      "|  10000.0|  1|        1|       2| 25|    low|   youth|[954.300966986551...|\n",
      "|  10000.0|  1|        1|       2| 25|    low|   youth|[954.300966986551...|\n",
      "|  10000.0|  1|        1|       2| 26|    low|   youth|[954.358477040145...|\n",
      "|  10000.0|  1|        1|       2| 27|    low|   youth|[954.409724954194...|\n",
      "|  10000.0|  1|        1|       2| 29|    low|   youth|[954.496793933561...|\n",
      "+---------+---+---------+--------+---+-------+--------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pipe.train_data_transformed.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "11f8cda1-9151-4daf-9165-64391a016ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "oneh = Custom_OneHotEncoder(input_columns=['BAL_CAT','maturity'],output_column='cat_features')\n",
    "indx,enc,ass = oneh.transform(train)\n",
    "\n",
    "Pipeline(stages=[index,enc,ass]).transform()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "071a759e-7fa4-42ef-8090-cc53adf4b598",
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = StringIndexer(inputCols=[\"BAL_CAT\",\"maturity\"],outputCols=[\"BAL_CAT_\",\"maturity_\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fbe5c7bb-4620-41cc-99d5-1d5f5e09ccbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = ind.fit(train).transform(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ce1f483e-0f59-4136-a480-960d5af7a98d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---+---------+--------+---+-------+--------+--------+---------+\n",
      "|LIMIT_BAL|SEX|EDUCATION|MARRIAGE|AGE|BAL_CAT|maturity|BAL_CAT_|maturity_|\n",
      "+---------+---+---------+--------+---+-------+--------+--------+---------+\n",
      "|    10000|  1|        1|       1| 38|    low|    yong|     0.0|      0.0|\n",
      "|    10000|  1|        1|       1| 40|    low|    yong|     0.0|      0.0|\n",
      "|    10000|  1|        1|       1| 48|    low|  mature|     0.0|      2.0|\n",
      "|    10000|  1|        1|       1| 50|    low|  mature|     0.0|      2.0|\n",
      "|    10000|  1|        1|       2| 22|    low|   youth|     0.0|      1.0|\n",
      "|    10000|  1|        1|       2| 22|    low|   youth|     0.0|      1.0|\n",
      "|    10000|  1|        1|       2| 23|    low|   youth|     0.0|      1.0|\n",
      "|    10000|  1|        1|       2| 23|    low|   youth|     0.0|      1.0|\n",
      "|    10000|  1|        1|       2| 23|    low|   youth|     0.0|      1.0|\n",
      "|    10000|  1|        1|       2| 23|    low|   youth|     0.0|      1.0|\n",
      "|    10000|  1|        1|       2| 24|    low|   youth|     0.0|      1.0|\n",
      "|    10000|  1|        1|       2| 24|    low|   youth|     0.0|      1.0|\n",
      "|    10000|  1|        1|       2| 24|    low|   youth|     0.0|      1.0|\n",
      "|    10000|  1|        1|       2| 24|    low|   youth|     0.0|      1.0|\n",
      "|    10000|  1|        1|       2| 25|    low|   youth|     0.0|      1.0|\n",
      "|    10000|  1|        1|       2| 25|    low|   youth|     0.0|      1.0|\n",
      "|    10000|  1|        1|       2| 25|    low|   youth|     0.0|      1.0|\n",
      "|    10000|  1|        1|       2| 26|    low|   youth|     0.0|      1.0|\n",
      "|    10000|  1|        1|       2| 27|    low|   youth|     0.0|      1.0|\n",
      "|    10000|  1|        1|       2| 29|    low|   youth|     0.0|      1.0|\n",
      "+---------+---+---------+--------+---+-------+--------+--------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "t.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "92874e7b-de87-4a9d-9ffd-af8937728270",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---+---------+--------+---+-------+--------+--------+---------+-------------+-------------+\n",
      "|LIMIT_BAL|SEX|EDUCATION|MARRIAGE|AGE|BAL_CAT|maturity|BAL_CAT_|maturity_|      bal_enc| maturity_enc|\n",
      "+---------+---+---------+--------+---+-------+--------+--------+---------+-------------+-------------+\n",
      "|    10000|  1|        1|       1| 38|    low|    yong|     0.0|      0.0|(3,[0],[1.0])|(3,[0],[1.0])|\n",
      "|    10000|  1|        1|       1| 40|    low|    yong|     0.0|      0.0|(3,[0],[1.0])|(3,[0],[1.0])|\n",
      "|    10000|  1|        1|       1| 48|    low|  mature|     0.0|      2.0|(3,[0],[1.0])|(3,[2],[1.0])|\n",
      "|    10000|  1|        1|       1| 50|    low|  mature|     0.0|      2.0|(3,[0],[1.0])|(3,[2],[1.0])|\n",
      "|    10000|  1|        1|       2| 22|    low|   youth|     0.0|      1.0|(3,[0],[1.0])|(3,[1],[1.0])|\n",
      "|    10000|  1|        1|       2| 22|    low|   youth|     0.0|      1.0|(3,[0],[1.0])|(3,[1],[1.0])|\n",
      "|    10000|  1|        1|       2| 23|    low|   youth|     0.0|      1.0|(3,[0],[1.0])|(3,[1],[1.0])|\n",
      "|    10000|  1|        1|       2| 23|    low|   youth|     0.0|      1.0|(3,[0],[1.0])|(3,[1],[1.0])|\n",
      "|    10000|  1|        1|       2| 23|    low|   youth|     0.0|      1.0|(3,[0],[1.0])|(3,[1],[1.0])|\n",
      "|    10000|  1|        1|       2| 23|    low|   youth|     0.0|      1.0|(3,[0],[1.0])|(3,[1],[1.0])|\n",
      "|    10000|  1|        1|       2| 24|    low|   youth|     0.0|      1.0|(3,[0],[1.0])|(3,[1],[1.0])|\n",
      "|    10000|  1|        1|       2| 24|    low|   youth|     0.0|      1.0|(3,[0],[1.0])|(3,[1],[1.0])|\n",
      "|    10000|  1|        1|       2| 24|    low|   youth|     0.0|      1.0|(3,[0],[1.0])|(3,[1],[1.0])|\n",
      "|    10000|  1|        1|       2| 24|    low|   youth|     0.0|      1.0|(3,[0],[1.0])|(3,[1],[1.0])|\n",
      "|    10000|  1|        1|       2| 25|    low|   youth|     0.0|      1.0|(3,[0],[1.0])|(3,[1],[1.0])|\n",
      "|    10000|  1|        1|       2| 25|    low|   youth|     0.0|      1.0|(3,[0],[1.0])|(3,[1],[1.0])|\n",
      "|    10000|  1|        1|       2| 25|    low|   youth|     0.0|      1.0|(3,[0],[1.0])|(3,[1],[1.0])|\n",
      "|    10000|  1|        1|       2| 26|    low|   youth|     0.0|      1.0|(3,[0],[1.0])|(3,[1],[1.0])|\n",
      "|    10000|  1|        1|       2| 27|    low|   youth|     0.0|      1.0|(3,[0],[1.0])|(3,[1],[1.0])|\n",
      "|    10000|  1|        1|       2| 29|    low|   youth|     0.0|      1.0|(3,[0],[1.0])|(3,[1],[1.0])|\n",
      "+---------+---+---------+--------+---+-------+--------+--------+---------+-------------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "enco = OneHotEncoder(inputCols=[\"BAL_CAT_\",\"maturity_\"],outputCols=['bal_enc','maturity_enc'],dropLast=False)\n",
    "e = enco.fit(t).transform(t)\n",
    "e.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "adea5a72-432b-4ddc-8fc2-dba623297356",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---+---------+--------+---+-------+--------+--------+---------+-------------+-------------+-------------------+\n",
      "|LIMIT_BAL|SEX|EDUCATION|MARRIAGE|AGE|BAL_CAT|maturity|BAL_CAT_|maturity_|      bal_enc| maturity_enc|        cat_feature|\n",
      "+---------+---+---------+--------+---+-------+--------+--------+---------+-------------+-------------+-------------------+\n",
      "|    10000|  1|        1|       1| 38|    low|    yong|     0.0|      0.0|(3,[0],[1.0])|(3,[0],[1.0])|(6,[0,3],[1.0,1.0])|\n",
      "|    10000|  1|        1|       1| 40|    low|    yong|     0.0|      0.0|(3,[0],[1.0])|(3,[0],[1.0])|(6,[0,3],[1.0,1.0])|\n",
      "|    10000|  1|        1|       1| 48|    low|  mature|     0.0|      2.0|(3,[0],[1.0])|(3,[2],[1.0])|(6,[0,5],[1.0,1.0])|\n",
      "|    10000|  1|        1|       1| 50|    low|  mature|     0.0|      2.0|(3,[0],[1.0])|(3,[2],[1.0])|(6,[0,5],[1.0,1.0])|\n",
      "|    10000|  1|        1|       2| 22|    low|   youth|     0.0|      1.0|(3,[0],[1.0])|(3,[1],[1.0])|(6,[0,4],[1.0,1.0])|\n",
      "|    10000|  1|        1|       2| 22|    low|   youth|     0.0|      1.0|(3,[0],[1.0])|(3,[1],[1.0])|(6,[0,4],[1.0,1.0])|\n",
      "|    10000|  1|        1|       2| 23|    low|   youth|     0.0|      1.0|(3,[0],[1.0])|(3,[1],[1.0])|(6,[0,4],[1.0,1.0])|\n",
      "|    10000|  1|        1|       2| 23|    low|   youth|     0.0|      1.0|(3,[0],[1.0])|(3,[1],[1.0])|(6,[0,4],[1.0,1.0])|\n",
      "|    10000|  1|        1|       2| 23|    low|   youth|     0.0|      1.0|(3,[0],[1.0])|(3,[1],[1.0])|(6,[0,4],[1.0,1.0])|\n",
      "|    10000|  1|        1|       2| 23|    low|   youth|     0.0|      1.0|(3,[0],[1.0])|(3,[1],[1.0])|(6,[0,4],[1.0,1.0])|\n",
      "|    10000|  1|        1|       2| 24|    low|   youth|     0.0|      1.0|(3,[0],[1.0])|(3,[1],[1.0])|(6,[0,4],[1.0,1.0])|\n",
      "|    10000|  1|        1|       2| 24|    low|   youth|     0.0|      1.0|(3,[0],[1.0])|(3,[1],[1.0])|(6,[0,4],[1.0,1.0])|\n",
      "|    10000|  1|        1|       2| 24|    low|   youth|     0.0|      1.0|(3,[0],[1.0])|(3,[1],[1.0])|(6,[0,4],[1.0,1.0])|\n",
      "|    10000|  1|        1|       2| 24|    low|   youth|     0.0|      1.0|(3,[0],[1.0])|(3,[1],[1.0])|(6,[0,4],[1.0,1.0])|\n",
      "|    10000|  1|        1|       2| 25|    low|   youth|     0.0|      1.0|(3,[0],[1.0])|(3,[1],[1.0])|(6,[0,4],[1.0,1.0])|\n",
      "|    10000|  1|        1|       2| 25|    low|   youth|     0.0|      1.0|(3,[0],[1.0])|(3,[1],[1.0])|(6,[0,4],[1.0,1.0])|\n",
      "|    10000|  1|        1|       2| 25|    low|   youth|     0.0|      1.0|(3,[0],[1.0])|(3,[1],[1.0])|(6,[0,4],[1.0,1.0])|\n",
      "|    10000|  1|        1|       2| 26|    low|   youth|     0.0|      1.0|(3,[0],[1.0])|(3,[1],[1.0])|(6,[0,4],[1.0,1.0])|\n",
      "|    10000|  1|        1|       2| 27|    low|   youth|     0.0|      1.0|(3,[0],[1.0])|(3,[1],[1.0])|(6,[0,4],[1.0,1.0])|\n",
      "|    10000|  1|        1|       2| 29|    low|   youth|     0.0|      1.0|(3,[0],[1.0])|(3,[1],[1.0])|(6,[0,4],[1.0,1.0])|\n",
      "+---------+---+---------+--------+---+-------+--------+--------+---------+-------------+-------------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vec = VectorAssembler(inputCols=['bal_enc','maturity_enc'],outputCol='cat_feature')\n",
    "vec.transform(e).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e055326b-e670-49a1-9865-06e3354d9b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "li = ['k','h']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "46565c1e-5e43-49ef-8f15-01e32c77f02e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'k_indh'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"_ind\".join(li)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f32ae307-91fb-4fb8-bedf-921c6be4fc6a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "32692823d3109f5bd75447dae6e1c6d928fc2410e760df9aa7f12324a979215b"
  },
  "kernelspec": {
   "display_name": "Python [conda env:SparkAutoML] *",
   "language": "python",
   "name": "conda-env-SparkAutoML-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
